{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "970e6ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout\n",
    "from IPython.display import display, Image\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.applications import ResNet50, DenseNet121, EfficientNetB0\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib.image as mpimg\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47ea63d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "jellyfish_dir = \"/aiffel/aiffel/jellyfish/\"\n",
    "# Define the path to the dataset folders\n",
    "Moon_jellyfish_folder = jellyfish_dir + \"Moon_jellyfish\"\n",
    "barrel_jellyfish_folder = jellyfish_dir + \"barrel_jellyfish\"\n",
    "blue_jellyfish_folder = jellyfish_dir + \"blue_jellyfish\"\n",
    "compass_jellyfish_folder = jellyfish_dir + \"compass_jellyfish\"\n",
    "lions_mane_jellyfish_folder = jellyfish_dir + \"lions_mane_jellyfish\"\n",
    "mauve_stinger_jellyfish_folder = jellyfish_dir + \"mauve_stinger_jellyfish\"\n",
    "\n",
    "\n",
    "\n",
    "# Function to load and preprocess images\n",
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv2.imread(os.path.join(folder, filename))\n",
    "        if img is not None:\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            img = cv2.resize(img, (224, 224))  # Resize to a fixed size for the model\n",
    "            images.append(img)\n",
    "    return images\n",
    "\n",
    "# Moon_jellyfish_folder = \"/kaggle/input/jellyfish-types/Moon_jellyfish\"\n",
    "# barrel_jellyfish_folder = \"/kaggle/input/jellyfish-types/barrel_jellyfish\"\n",
    "# blue_jellyfish_folder = \"/kaggle/input/jellyfish-types/blue_jellyfish\"\n",
    "# compass_jellyfish_folder = \"/kaggle/input/jellyfish-types/compass_jellyfish\"\n",
    "# lions_mane_jellyfish_folder = \"/kaggle/input/jellyfish-types/lions_mane_jellyfish\"\n",
    "# mauve_stinger_jellyfish_folder = \"/kaggle/input/jellyfish-types/mauve_stinger_jellyfish\"\n",
    "\n",
    "# Load images and labels for each emotion\n",
    "Moon_images = load_images_from_folder(Moon_jellyfish_folder)\n",
    "barrel_images = load_images_from_folder(barrel_jellyfish_folder)\n",
    "blue_images = load_images_from_folder(blue_jellyfish_folder)\n",
    "compass_images = load_images_from_folder(compass_jellyfish_folder)\n",
    "lions_mane_images = load_images_from_folder(lions_mane_jellyfish_folder)\n",
    "mauve_stinger_images = load_images_from_folder(mauve_stinger_jellyfish_folder)\n",
    "\n",
    "\n",
    "# Create labels for each emotion category\n",
    "Moon_labels = [0] * len(Moon_images)\n",
    "barrel_labels = [1] * len(barrel_images)\n",
    "blue_labels = [2] * len(blue_images)\n",
    "compass_labels = [3] * len(compass_images)\n",
    "lions_mane_labels = [4] * len(lions_mane_images)\n",
    "mauve_stinger_labels = [5] * len(mauve_stinger_images)\n",
    "\n",
    "all_labels = Moon_labels+barrel_labels+blue_labels+compass_labels+lions_mane_labels+mauve_stinger_labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b08437d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "900"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b21b9c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moon_jellyfish_images:  150\n",
      "barrel_jellyfish_images:  150\n",
      "blue_jellyfish_images:  150\n",
      "compass_jellyfish_images:  150\n",
      "lions_mane_jellyfish_images:  150\n",
      "mauve_stinger_jellyfish_images:  150\n"
     ]
    }
   ],
   "source": [
    "print('Moon_jellyfish_images: ',len(Moon_images))\n",
    "print('barrel_jellyfish_images: ',len(barrel_images))\n",
    "print('blue_jellyfish_images: ',len(blue_images))\n",
    "print('compass_jellyfish_images: ',len(compass_images))\n",
    "print('lions_mane_jellyfish_images: ',len(lions_mane_images))\n",
    "print('mauve_stinger_jellyfish_images: ',len(mauve_stinger_images))\n",
    "Moon_jellyfish_images:  150\n",
    "barrel_jellyfish_images:  150\n",
    "blue_jellyfish_images:  150\n",
    "compass_jellyfish_images:  150\n",
    "lions_mane_jellyfish_images:  150\n",
    "mauve_stinger_jellyfish_images:  150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24ed3750",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Data Imbalance\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(8, 3))\n",
    "sns.countplot(x=all_labels, hue=all_labels)\n",
    "plt.title('Data Imbalance')\n",
    "plt.xlabel('Jellyfish species')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3177b13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate images and labels\n",
    "X = np.array(Moon_images + barrel_images + blue_images + compass_images + lions_mane_images + mauve_stinger_images)\n",
    "y = np.array(Moon_labels + barrel_labels + blue_labels + compass_labels + lions_mane_labels + mauve_stinger_labels)\n",
    "\n",
    "# Normalize pixel values to range [0, 1]\n",
    "X = X.astype('float32') / 255.0\n",
    "\n",
    "# One-hot encode the labels\n",
    "y = np_utils.to_categorical(y, 6)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7113b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape_resnet = (224, 224, 3)\n",
    "input_shape_densenet = (224, 224, 3)\n",
    "input_shape_efficientnet = (224, 224, 3)\n",
    "\n",
    "def resize_images(images, input_shape):\n",
    "    resized_images = []\n",
    "    for img in images:\n",
    "        img_resized = cv2.resize(img, (input_shape[0], input_shape[1]))\n",
    "        img_resized = np.expand_dims(img_resized, axis=-1)\n",
    "        img_resized = np.repeat(img_resized, 3, axis=-1)  # Add three channels to convert grayscale to RGB\n",
    "        resized_images.append(img_resized)\n",
    "    return np.array(resized_images)\n",
    "\n",
    "X_train_resized_resnet = resize_images(X_train, input_shape_resnet)\n",
    "X_train_resized_densenet = resize_images(X_train, input_shape_densenet)\n",
    "X_train_resized_efficientnet = resize_images(X_train, input_shape_efficientnet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc4bae1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94773248/94765736 [==============================] - 0s 0us/step\n",
      "94781440/94765736 [==============================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "29089792/29084464 [==============================] - 0s 0us/step\n",
      "29097984/29084464 [==============================] - 0s 0us/step\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 44s 216ms/step - loss: 1.8301 - accuracy: 0.1493 - val_loss: 1.8359 - val_accuracy: 0.1667\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.8007 - accuracy: 0.1597 - val_loss: 1.7924 - val_accuracy: 0.1944\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 2s 119ms/step - loss: 1.7937 - accuracy: 0.1875 - val_loss: 1.8095 - val_accuracy: 0.1806\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 2s 119ms/step - loss: 1.7940 - accuracy: 0.1875 - val_loss: 1.7861 - val_accuracy: 0.1667\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 2s 120ms/step - loss: 1.7873 - accuracy: 0.1892 - val_loss: 1.7662 - val_accuracy: 0.2917\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 2s 120ms/step - loss: 1.7704 - accuracy: 0.1962 - val_loss: 1.7743 - val_accuracy: 0.2361\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 2s 120ms/step - loss: 1.7744 - accuracy: 0.2240 - val_loss: 1.7451 - val_accuracy: 0.2431\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 2s 121ms/step - loss: 1.7635 - accuracy: 0.2118 - val_loss: 1.7593 - val_accuracy: 0.2083\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 2s 121ms/step - loss: 1.7591 - accuracy: 0.2170 - val_loss: 1.7416 - val_accuracy: 0.2361\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 2s 122ms/step - loss: 1.7622 - accuracy: 0.2378 - val_loss: 1.7436 - val_accuracy: 0.1736\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 2s 122ms/step - loss: 1.7531 - accuracy: 0.2656 - val_loss: 1.7700 - val_accuracy: 0.2292\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 2s 121ms/step - loss: 1.7523 - accuracy: 0.2604 - val_loss: 1.7188 - val_accuracy: 0.2778\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 2s 119ms/step - loss: 1.7423 - accuracy: 0.2535 - val_loss: 1.7448 - val_accuracy: 0.2500\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 2s 121ms/step - loss: 1.7332 - accuracy: 0.2708 - val_loss: 1.7152 - val_accuracy: 0.2222\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 2s 121ms/step - loss: 1.7440 - accuracy: 0.2240 - val_loss: 1.7331 - val_accuracy: 0.2222\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 2s 120ms/step - loss: 1.7437 - accuracy: 0.2309 - val_loss: 1.7177 - val_accuracy: 0.2639\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 2s 119ms/step - loss: 1.7315 - accuracy: 0.2413 - val_loss: 1.7077 - val_accuracy: 0.2361\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 2s 119ms/step - loss: 1.7247 - accuracy: 0.2587 - val_loss: 1.7193 - val_accuracy: 0.2222\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 2s 119ms/step - loss: 1.7176 - accuracy: 0.2535 - val_loss: 1.6970 - val_accuracy: 0.3125\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 2s 119ms/step - loss: 1.7122 - accuracy: 0.2587 - val_loss: 1.6923 - val_accuracy: 0.2847\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.7128 - accuracy: 0.2604 - val_loss: 1.6788 - val_accuracy: 0.3056\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.7284 - accuracy: 0.2587 - val_loss: 1.7326 - val_accuracy: 0.1875\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.7119 - accuracy: 0.2743 - val_loss: 1.6869 - val_accuracy: 0.2847\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - 2s 119ms/step - loss: 1.7025 - accuracy: 0.2760 - val_loss: 1.6918 - val_accuracy: 0.2222\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.7010 - accuracy: 0.2622 - val_loss: 1.6836 - val_accuracy: 0.3125\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.6993 - accuracy: 0.2830 - val_loss: 1.6754 - val_accuracy: 0.3125\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.7056 - accuracy: 0.2569 - val_loss: 1.6616 - val_accuracy: 0.3194\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - 2s 119ms/step - loss: 1.6969 - accuracy: 0.2847 - val_loss: 1.6969 - val_accuracy: 0.2500\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.6904 - accuracy: 0.2882 - val_loss: 1.6637 - val_accuracy: 0.3264\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.6862 - accuracy: 0.3160 - val_loss: 1.6643 - val_accuracy: 0.3264\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.6790 - accuracy: 0.3142 - val_loss: 1.6628 - val_accuracy: 0.3611\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.6791 - accuracy: 0.3021 - val_loss: 1.6490 - val_accuracy: 0.3542\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.6879 - accuracy: 0.2465 - val_loss: 1.6665 - val_accuracy: 0.3264\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.6894 - accuracy: 0.2795 - val_loss: 1.7021 - val_accuracy: 0.2431\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.6924 - accuracy: 0.2743 - val_loss: 1.6672 - val_accuracy: 0.3403\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.6825 - accuracy: 0.3177 - val_loss: 1.6472 - val_accuracy: 0.3403\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.6761 - accuracy: 0.2882 - val_loss: 1.6464 - val_accuracy: 0.3333\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.6615 - accuracy: 0.3299 - val_loss: 1.6539 - val_accuracy: 0.3333\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.6662 - accuracy: 0.3212 - val_loss: 1.6611 - val_accuracy: 0.3056\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - 2s 119ms/step - loss: 1.6578 - accuracy: 0.3316 - val_loss: 1.6571 - val_accuracy: 0.3125\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.6596 - accuracy: 0.3194 - val_loss: 1.6344 - val_accuracy: 0.3889\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - 2s 119ms/step - loss: 1.6580 - accuracy: 0.3229 - val_loss: 1.6436 - val_accuracy: 0.3264\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.6645 - accuracy: 0.3003 - val_loss: 1.6606 - val_accuracy: 0.3194\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.6623 - accuracy: 0.3264 - val_loss: 1.6352 - val_accuracy: 0.3611\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.6467 - accuracy: 0.3229 - val_loss: 1.6217 - val_accuracy: 0.3750\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - 2s 119ms/step - loss: 1.6387 - accuracy: 0.3576 - val_loss: 1.6387 - val_accuracy: 0.3542\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.6460 - accuracy: 0.3160 - val_loss: 1.6358 - val_accuracy: 0.3264\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - 2s 119ms/step - loss: 1.6590 - accuracy: 0.3299 - val_loss: 1.6332 - val_accuracy: 0.3611\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.6409 - accuracy: 0.3316 - val_loss: 1.6091 - val_accuracy: 0.3125\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - 2s 119ms/step - loss: 1.6409 - accuracy: 0.3455 - val_loss: 1.6694 - val_accuracy: 0.3125\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - 2s 120ms/step - loss: 1.6552 - accuracy: 0.3073 - val_loss: 1.6252 - val_accuracy: 0.3611\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.6410 - accuracy: 0.3264 - val_loss: 1.6261 - val_accuracy: 0.3542\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - 2s 119ms/step - loss: 1.6274 - accuracy: 0.3142 - val_loss: 1.6505 - val_accuracy: 0.3472\n",
      "Epoch 54/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 2s 118ms/step - loss: 1.6511 - accuracy: 0.3247 - val_loss: 1.6099 - val_accuracy: 0.3403\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.6313 - accuracy: 0.3750 - val_loss: 1.6160 - val_accuracy: 0.3958\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - 2s 119ms/step - loss: 1.6261 - accuracy: 0.3524 - val_loss: 1.6207 - val_accuracy: 0.4097\n",
      "Epoch 57/200\n",
      "18/18 [==============================] - 2s 119ms/step - loss: 1.6218 - accuracy: 0.3559 - val_loss: 1.6381 - val_accuracy: 0.3194\n",
      "Epoch 58/200\n",
      "18/18 [==============================] - 2s 117ms/step - loss: 1.6254 - accuracy: 0.3264 - val_loss: 1.6116 - val_accuracy: 0.3750\n",
      "Epoch 59/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.6208 - accuracy: 0.3368 - val_loss: 1.6442 - val_accuracy: 0.2639\n",
      "Epoch 60/200\n",
      "18/18 [==============================] - 2s 131ms/step - loss: 1.6194 - accuracy: 0.3490 - val_loss: 1.5987 - val_accuracy: 0.3750\n",
      "Epoch 61/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.6119 - accuracy: 0.3455 - val_loss: 1.6130 - val_accuracy: 0.3194\n",
      "Epoch 62/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.6167 - accuracy: 0.3576 - val_loss: 1.5987 - val_accuracy: 0.4097\n",
      "Epoch 63/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.6078 - accuracy: 0.3490 - val_loss: 1.5997 - val_accuracy: 0.3611\n",
      "Epoch 64/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.6044 - accuracy: 0.3872 - val_loss: 1.5975 - val_accuracy: 0.3750\n",
      "Epoch 65/200\n",
      "18/18 [==============================] - 2s 119ms/step - loss: 1.6121 - accuracy: 0.3455 - val_loss: 1.6006 - val_accuracy: 0.3958\n",
      "Epoch 66/200\n",
      "18/18 [==============================] - 2s 119ms/step - loss: 1.6141 - accuracy: 0.3698 - val_loss: 1.5954 - val_accuracy: 0.3889\n",
      "Epoch 67/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.6039 - accuracy: 0.3681 - val_loss: 1.5987 - val_accuracy: 0.3611\n",
      "Epoch 68/200\n",
      "18/18 [==============================] - 2s 117ms/step - loss: 1.6067 - accuracy: 0.3507 - val_loss: 1.6039 - val_accuracy: 0.3958\n",
      "Epoch 69/200\n",
      "18/18 [==============================] - 2s 117ms/step - loss: 1.6082 - accuracy: 0.3854 - val_loss: 1.5998 - val_accuracy: 0.3819\n",
      "Epoch 70/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.6052 - accuracy: 0.3490 - val_loss: 1.5946 - val_accuracy: 0.3611\n",
      "Epoch 71/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.5986 - accuracy: 0.3767 - val_loss: 1.5921 - val_accuracy: 0.3889\n",
      "Epoch 72/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.6007 - accuracy: 0.3958 - val_loss: 1.5934 - val_accuracy: 0.3889\n",
      "Epoch 73/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.6037 - accuracy: 0.3576 - val_loss: 1.5940 - val_accuracy: 0.3819\n",
      "Epoch 74/200\n",
      "18/18 [==============================] - 2s 119ms/step - loss: 1.6014 - accuracy: 0.3993 - val_loss: 1.5950 - val_accuracy: 0.4167\n",
      "Epoch 75/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.6001 - accuracy: 0.3698 - val_loss: 1.5918 - val_accuracy: 0.3819\n",
      "Epoch 76/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.6001 - accuracy: 0.3524 - val_loss: 1.5939 - val_accuracy: 0.4028\n",
      "Epoch 77/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.6061 - accuracy: 0.3611 - val_loss: 1.5866 - val_accuracy: 0.3681\n",
      "Epoch 78/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.6020 - accuracy: 0.3576 - val_loss: 1.5952 - val_accuracy: 0.3611\n",
      "Epoch 79/200\n",
      "18/18 [==============================] - 2s 119ms/step - loss: 1.6027 - accuracy: 0.3628 - val_loss: 1.5859 - val_accuracy: 0.3611\n",
      "Epoch 80/200\n",
      "18/18 [==============================] - 2s 119ms/step - loss: 1.5934 - accuracy: 0.3837 - val_loss: 1.5932 - val_accuracy: 0.3681\n",
      "Epoch 81/200\n",
      "18/18 [==============================] - 2s 119ms/step - loss: 1.5944 - accuracy: 0.3767 - val_loss: 1.5836 - val_accuracy: 0.3472\n",
      "Epoch 82/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.5915 - accuracy: 0.3854 - val_loss: 1.5886 - val_accuracy: 0.3611\n",
      "Epoch 83/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.5925 - accuracy: 0.3750 - val_loss: 1.5833 - val_accuracy: 0.3750\n",
      "Epoch 84/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.5926 - accuracy: 0.3941 - val_loss: 1.5860 - val_accuracy: 0.3750\n",
      "Epoch 85/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.5932 - accuracy: 0.3542 - val_loss: 1.5863 - val_accuracy: 0.3958\n",
      "Epoch 86/200\n",
      "18/18 [==============================] - 2s 117ms/step - loss: 1.5879 - accuracy: 0.4062 - val_loss: 1.5901 - val_accuracy: 0.3750\n",
      "Epoch 87/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.5907 - accuracy: 0.3715 - val_loss: 1.5900 - val_accuracy: 0.4097\n",
      "Epoch 88/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.5851 - accuracy: 0.4062 - val_loss: 1.5819 - val_accuracy: 0.3819\n",
      "Epoch 89/200\n",
      "18/18 [==============================] - 2s 119ms/step - loss: 1.5924 - accuracy: 0.3785 - val_loss: 1.5862 - val_accuracy: 0.3611\n",
      "Epoch 90/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.5873 - accuracy: 0.3819 - val_loss: 1.5778 - val_accuracy: 0.3819\n",
      "Epoch 91/200\n",
      "18/18 [==============================] - 2s 119ms/step - loss: 1.5870 - accuracy: 0.4028 - val_loss: 1.5833 - val_accuracy: 0.3750\n",
      "Epoch 92/200\n",
      "18/18 [==============================] - 2s 119ms/step - loss: 1.5847 - accuracy: 0.3785 - val_loss: 1.5784 - val_accuracy: 0.3611\n",
      "Epoch 93/200\n",
      "18/18 [==============================] - 2s 119ms/step - loss: 1.5868 - accuracy: 0.3767 - val_loss: 1.5787 - val_accuracy: 0.3750\n",
      "Epoch 94/200\n",
      "18/18 [==============================] - 2s 119ms/step - loss: 1.5837 - accuracy: 0.3924 - val_loss: 1.5793 - val_accuracy: 0.3889\n",
      "Epoch 95/200\n",
      "18/18 [==============================] - 2s 119ms/step - loss: 1.5858 - accuracy: 0.3767 - val_loss: 1.5821 - val_accuracy: 0.3958\n",
      "Epoch 96/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.5774 - accuracy: 0.3993 - val_loss: 1.5834 - val_accuracy: 0.3611\n",
      "Epoch 97/200\n",
      "18/18 [==============================] - 2s 120ms/step - loss: 1.5801 - accuracy: 0.3819 - val_loss: 1.5742 - val_accuracy: 0.3819\n",
      "Epoch 98/200\n",
      "18/18 [==============================] - 2s 119ms/step - loss: 1.5785 - accuracy: 0.3906 - val_loss: 1.5715 - val_accuracy: 0.4028\n",
      "Epoch 99/200\n",
      "18/18 [==============================] - 2s 119ms/step - loss: 1.5813 - accuracy: 0.3819 - val_loss: 1.5715 - val_accuracy: 0.3681\n",
      "Epoch 100/200\n",
      "18/18 [==============================] - 2s 117ms/step - loss: 1.5769 - accuracy: 0.3681 - val_loss: 1.5769 - val_accuracy: 0.4236\n",
      "Epoch 101/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.5763 - accuracy: 0.4097 - val_loss: 1.5733 - val_accuracy: 0.3750\n",
      "Epoch 102/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.5777 - accuracy: 0.3750 - val_loss: 1.5758 - val_accuracy: 0.3611\n",
      "Epoch 103/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.5804 - accuracy: 0.3750 - val_loss: 1.5737 - val_accuracy: 0.3611\n",
      "Epoch 104/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.5778 - accuracy: 0.3802 - val_loss: 1.5672 - val_accuracy: 0.3958\n",
      "Epoch 105/200\n",
      "18/18 [==============================] - 2s 119ms/step - loss: 1.5722 - accuracy: 0.3906 - val_loss: 1.5739 - val_accuracy: 0.4167\n",
      "Epoch 106/200\n",
      "18/18 [==============================] - 2s 119ms/step - loss: 1.5807 - accuracy: 0.3646 - val_loss: 1.5788 - val_accuracy: 0.3750\n",
      "Epoch 107/200\n",
      "18/18 [==============================] - 2s 119ms/step - loss: 1.5782 - accuracy: 0.3715 - val_loss: 1.5700 - val_accuracy: 0.3958\n",
      "Epoch 108/200\n",
      "18/18 [==============================] - 2s 119ms/step - loss: 1.5693 - accuracy: 0.4080 - val_loss: 1.5726 - val_accuracy: 0.3958\n",
      "Epoch 109/200\n",
      "18/18 [==============================] - 2s 119ms/step - loss: 1.5756 - accuracy: 0.3785 - val_loss: 1.5728 - val_accuracy: 0.4028\n",
      "Epoch 110/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.5729 - accuracy: 0.3958 - val_loss: 1.5711 - val_accuracy: 0.3681\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.5694 - accuracy: 0.4028 - val_loss: 1.5692 - val_accuracy: 0.3681\n",
      "Epoch 112/200\n",
      "18/18 [==============================] - 2s 119ms/step - loss: 1.5663 - accuracy: 0.3854 - val_loss: 1.5661 - val_accuracy: 0.3819\n",
      "Epoch 113/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.5693 - accuracy: 0.3872 - val_loss: 1.5733 - val_accuracy: 0.4167\n",
      "Epoch 114/200\n",
      "18/18 [==============================] - 2s 119ms/step - loss: 1.5664 - accuracy: 0.3837 - val_loss: 1.5675 - val_accuracy: 0.3958\n",
      "Epoch 115/200\n",
      "18/18 [==============================] - 2s 119ms/step - loss: 1.5630 - accuracy: 0.4028 - val_loss: 1.5695 - val_accuracy: 0.3889\n",
      "Epoch 116/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.5643 - accuracy: 0.4097 - val_loss: 1.5634 - val_accuracy: 0.3472\n",
      "Epoch 117/200\n",
      "18/18 [==============================] - 2s 119ms/step - loss: 1.5687 - accuracy: 0.3837 - val_loss: 1.5672 - val_accuracy: 0.3681\n",
      "Epoch 118/200\n",
      "18/18 [==============================] - 2s 119ms/step - loss: 1.5651 - accuracy: 0.4097 - val_loss: 1.5618 - val_accuracy: 0.4167\n",
      "Epoch 119/200\n",
      "18/18 [==============================] - 2s 119ms/step - loss: 1.5678 - accuracy: 0.3750 - val_loss: 1.5683 - val_accuracy: 0.3819\n",
      "Epoch 120/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.5613 - accuracy: 0.4115 - val_loss: 1.5606 - val_accuracy: 0.3889\n",
      "Epoch 121/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.5591 - accuracy: 0.4010 - val_loss: 1.5708 - val_accuracy: 0.4028\n",
      "Epoch 122/200\n",
      "18/18 [==============================] - 2s 119ms/step - loss: 1.5632 - accuracy: 0.3802 - val_loss: 1.5681 - val_accuracy: 0.3889\n",
      "Epoch 123/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.5641 - accuracy: 0.3819 - val_loss: 1.5570 - val_accuracy: 0.4028\n",
      "Epoch 124/200\n",
      "18/18 [==============================] - 2s 119ms/step - loss: 1.5632 - accuracy: 0.3872 - val_loss: 1.5669 - val_accuracy: 0.3611\n",
      "Epoch 125/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.5541 - accuracy: 0.4201 - val_loss: 1.5548 - val_accuracy: 0.3819\n",
      "Epoch 126/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.5619 - accuracy: 0.3854 - val_loss: 1.5668 - val_accuracy: 0.4097\n",
      "Epoch 127/200\n",
      "18/18 [==============================] - 2s 117ms/step - loss: 1.5607 - accuracy: 0.4045 - val_loss: 1.5562 - val_accuracy: 0.3750\n",
      "Epoch 128/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.5581 - accuracy: 0.4028 - val_loss: 1.5551 - val_accuracy: 0.3958\n",
      "Epoch 129/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.5557 - accuracy: 0.3906 - val_loss: 1.5584 - val_accuracy: 0.3681\n",
      "Epoch 130/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.5550 - accuracy: 0.4010 - val_loss: 1.5621 - val_accuracy: 0.3611\n",
      "Epoch 131/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.5585 - accuracy: 0.3681 - val_loss: 1.5603 - val_accuracy: 0.4097\n",
      "Epoch 132/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.5582 - accuracy: 0.4115 - val_loss: 1.5559 - val_accuracy: 0.4167\n",
      "Epoch 133/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.5531 - accuracy: 0.4028 - val_loss: 1.5635 - val_accuracy: 0.4028\n",
      "Epoch 134/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.5481 - accuracy: 0.4288 - val_loss: 1.5571 - val_accuracy: 0.4028\n",
      "Epoch 135/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.5521 - accuracy: 0.3854 - val_loss: 1.5488 - val_accuracy: 0.3611\n",
      "Epoch 136/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.5557 - accuracy: 0.3976 - val_loss: 1.5682 - val_accuracy: 0.4097\n",
      "Epoch 137/200\n",
      "18/18 [==============================] - 2s 117ms/step - loss: 1.5511 - accuracy: 0.3924 - val_loss: 1.5505 - val_accuracy: 0.3611\n",
      "Epoch 138/200\n",
      "18/18 [==============================] - 2s 119ms/step - loss: 1.5477 - accuracy: 0.3976 - val_loss: 1.5570 - val_accuracy: 0.4097\n",
      "Epoch 139/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.5479 - accuracy: 0.4080 - val_loss: 1.5518 - val_accuracy: 0.3889\n",
      "Epoch 140/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.5464 - accuracy: 0.4132 - val_loss: 1.5529 - val_accuracy: 0.3819\n",
      "Epoch 141/200\n",
      "18/18 [==============================] - 2s 119ms/step - loss: 1.5450 - accuracy: 0.4167 - val_loss: 1.5561 - val_accuracy: 0.3958\n",
      "Epoch 142/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.5402 - accuracy: 0.4132 - val_loss: 1.5469 - val_accuracy: 0.3681\n",
      "Epoch 143/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.5542 - accuracy: 0.4010 - val_loss: 1.5561 - val_accuracy: 0.3611\n",
      "Epoch 144/200\n",
      "18/18 [==============================] - 2s 117ms/step - loss: 1.5435 - accuracy: 0.3802 - val_loss: 1.5451 - val_accuracy: 0.3681\n",
      "Epoch 145/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.5435 - accuracy: 0.3958 - val_loss: 1.5561 - val_accuracy: 0.4028\n",
      "Epoch 146/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.5419 - accuracy: 0.4462 - val_loss: 1.5450 - val_accuracy: 0.3611\n",
      "Epoch 147/200\n",
      "18/18 [==============================] - 2s 119ms/step - loss: 1.5499 - accuracy: 0.3767 - val_loss: 1.5490 - val_accuracy: 0.3750\n",
      "Epoch 148/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.5439 - accuracy: 0.4149 - val_loss: 1.5492 - val_accuracy: 0.3611\n",
      "Epoch 149/200\n",
      "18/18 [==============================] - 2s 117ms/step - loss: 1.5433 - accuracy: 0.4219 - val_loss: 1.5498 - val_accuracy: 0.4097\n",
      "Epoch 150/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.5394 - accuracy: 0.3941 - val_loss: 1.5473 - val_accuracy: 0.4028\n",
      "Epoch 151/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.5465 - accuracy: 0.3837 - val_loss: 1.5441 - val_accuracy: 0.3681\n",
      "Epoch 152/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.5399 - accuracy: 0.3837 - val_loss: 1.5474 - val_accuracy: 0.3958\n",
      "Epoch 153/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.5441 - accuracy: 0.4080 - val_loss: 1.5413 - val_accuracy: 0.4028\n",
      "Epoch 154/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.5395 - accuracy: 0.4062 - val_loss: 1.5452 - val_accuracy: 0.3819\n",
      "Epoch 155/200\n",
      "18/18 [==============================] - 2s 119ms/step - loss: 1.5399 - accuracy: 0.4010 - val_loss: 1.5484 - val_accuracy: 0.3819\n",
      "Epoch 156/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.5401 - accuracy: 0.4184 - val_loss: 1.5446 - val_accuracy: 0.4028\n",
      "Epoch 157/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.5411 - accuracy: 0.3872 - val_loss: 1.5442 - val_accuracy: 0.4375\n",
      "Epoch 158/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.5362 - accuracy: 0.4097 - val_loss: 1.5425 - val_accuracy: 0.3819\n",
      "Epoch 159/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.5294 - accuracy: 0.4201 - val_loss: 1.5423 - val_accuracy: 0.3750\n",
      "Epoch 160/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.5352 - accuracy: 0.4080 - val_loss: 1.5408 - val_accuracy: 0.3958\n",
      "Epoch 161/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.5308 - accuracy: 0.4271 - val_loss: 1.5448 - val_accuracy: 0.3750\n",
      "Epoch 162/200\n",
      "18/18 [==============================] - 2s 119ms/step - loss: 1.5316 - accuracy: 0.3941 - val_loss: 1.5402 - val_accuracy: 0.4028\n",
      "Epoch 163/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.5339 - accuracy: 0.4149 - val_loss: 1.5499 - val_accuracy: 0.3819\n",
      "Epoch 164/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.5310 - accuracy: 0.4236 - val_loss: 1.5431 - val_accuracy: 0.3819\n",
      "Epoch 165/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.5303 - accuracy: 0.4184 - val_loss: 1.5435 - val_accuracy: 0.4097\n",
      "Epoch 166/200\n",
      "18/18 [==============================] - 2s 117ms/step - loss: 1.5260 - accuracy: 0.4219 - val_loss: 1.5414 - val_accuracy: 0.3889\n",
      "Epoch 167/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 2s 118ms/step - loss: 1.5256 - accuracy: 0.4288 - val_loss: 1.5447 - val_accuracy: 0.3750\n",
      "Epoch 168/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.5299 - accuracy: 0.4028 - val_loss: 1.5389 - val_accuracy: 0.4028\n",
      "Epoch 169/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.5253 - accuracy: 0.4219 - val_loss: 1.5328 - val_accuracy: 0.3958\n",
      "Epoch 170/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.5236 - accuracy: 0.4132 - val_loss: 1.5400 - val_accuracy: 0.4028\n",
      "Epoch 171/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.5232 - accuracy: 0.4410 - val_loss: 1.5386 - val_accuracy: 0.4167\n",
      "Epoch 172/200\n",
      "18/18 [==============================] - 2s 117ms/step - loss: 1.5244 - accuracy: 0.4080 - val_loss: 1.5363 - val_accuracy: 0.3958\n",
      "Epoch 173/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.5363 - accuracy: 0.3906 - val_loss: 1.5396 - val_accuracy: 0.3889\n",
      "Epoch 174/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.5296 - accuracy: 0.4062 - val_loss: 1.5326 - val_accuracy: 0.3681\n",
      "Epoch 175/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.5274 - accuracy: 0.4306 - val_loss: 1.5359 - val_accuracy: 0.4028\n",
      "Epoch 176/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.5198 - accuracy: 0.4062 - val_loss: 1.5336 - val_accuracy: 0.4028\n",
      "Epoch 177/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.5263 - accuracy: 0.4115 - val_loss: 1.5450 - val_accuracy: 0.4167\n",
      "Epoch 178/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.5215 - accuracy: 0.4323 - val_loss: 1.5252 - val_accuracy: 0.3750\n",
      "Epoch 179/200\n",
      "18/18 [==============================] - 2s 119ms/step - loss: 1.5251 - accuracy: 0.3976 - val_loss: 1.5323 - val_accuracy: 0.4236\n",
      "Epoch 180/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.5235 - accuracy: 0.4097 - val_loss: 1.5334 - val_accuracy: 0.3542\n",
      "Epoch 181/200\n",
      "18/18 [==============================] - 2s 119ms/step - loss: 1.5216 - accuracy: 0.4323 - val_loss: 1.5389 - val_accuracy: 0.4167\n",
      "Epoch 182/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.5208 - accuracy: 0.4288 - val_loss: 1.5269 - val_accuracy: 0.3611\n",
      "Epoch 183/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.5268 - accuracy: 0.4045 - val_loss: 1.5399 - val_accuracy: 0.4097\n",
      "Epoch 184/200\n",
      "18/18 [==============================] - 2s 119ms/step - loss: 1.5250 - accuracy: 0.4045 - val_loss: 1.5280 - val_accuracy: 0.4028\n",
      "Epoch 185/200\n",
      "18/18 [==============================] - 2s 117ms/step - loss: 1.5258 - accuracy: 0.4253 - val_loss: 1.5275 - val_accuracy: 0.3750\n",
      "Epoch 186/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.5173 - accuracy: 0.3976 - val_loss: 1.5275 - val_accuracy: 0.4375\n",
      "Epoch 187/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.5197 - accuracy: 0.4080 - val_loss: 1.5308 - val_accuracy: 0.4306\n",
      "Epoch 188/200\n",
      "18/18 [==============================] - 2s 117ms/step - loss: 1.5153 - accuracy: 0.4097 - val_loss: 1.5382 - val_accuracy: 0.3750\n",
      "Epoch 189/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.5145 - accuracy: 0.4097 - val_loss: 1.5380 - val_accuracy: 0.3958\n",
      "Epoch 190/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.5087 - accuracy: 0.4375 - val_loss: 1.5272 - val_accuracy: 0.4306\n",
      "Epoch 191/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.5089 - accuracy: 0.4236 - val_loss: 1.5268 - val_accuracy: 0.3681\n",
      "Epoch 192/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.5095 - accuracy: 0.4427 - val_loss: 1.5332 - val_accuracy: 0.4167\n",
      "Epoch 193/200\n",
      "18/18 [==============================] - 2s 119ms/step - loss: 1.5088 - accuracy: 0.4201 - val_loss: 1.5278 - val_accuracy: 0.3750\n",
      "Epoch 194/200\n",
      "18/18 [==============================] - 2s 119ms/step - loss: 1.5071 - accuracy: 0.4358 - val_loss: 1.5291 - val_accuracy: 0.4167\n",
      "Epoch 195/200\n",
      "18/18 [==============================] - 2s 117ms/step - loss: 1.5080 - accuracy: 0.4358 - val_loss: 1.5288 - val_accuracy: 0.4028\n",
      "Epoch 196/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.5059 - accuracy: 0.4340 - val_loss: 1.5285 - val_accuracy: 0.4028\n",
      "Epoch 197/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.5067 - accuracy: 0.4392 - val_loss: 1.5269 - val_accuracy: 0.4028\n",
      "Epoch 198/200\n",
      "18/18 [==============================] - 2s 117ms/step - loss: 1.5071 - accuracy: 0.4288 - val_loss: 1.5242 - val_accuracy: 0.4097\n",
      "Epoch 199/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.5058 - accuracy: 0.4253 - val_loss: 1.5312 - val_accuracy: 0.3681\n",
      "Epoch 200/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.5055 - accuracy: 0.4306 - val_loss: 1.5268 - val_accuracy: 0.4236\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 12s 288ms/step - loss: 1.8948 - accuracy: 0.2326 - val_loss: 1.4554 - val_accuracy: 0.4861\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 2s 115ms/step - loss: 1.3011 - accuracy: 0.5226 - val_loss: 1.0604 - val_accuracy: 0.6528\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.9788 - accuracy: 0.6910 - val_loss: 0.8687 - val_accuracy: 0.7361\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.7916 - accuracy: 0.7708 - val_loss: 0.7237 - val_accuracy: 0.7847\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 2s 115ms/step - loss: 0.6685 - accuracy: 0.8038 - val_loss: 0.6411 - val_accuracy: 0.8125\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 2s 117ms/step - loss: 0.5828 - accuracy: 0.8316 - val_loss: 0.5752 - val_accuracy: 0.8333\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 2s 117ms/step - loss: 0.5213 - accuracy: 0.8542 - val_loss: 0.5366 - val_accuracy: 0.8403\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 2s 117ms/step - loss: 0.4769 - accuracy: 0.8715 - val_loss: 0.5098 - val_accuracy: 0.8611\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 2s 117ms/step - loss: 0.4436 - accuracy: 0.8872 - val_loss: 0.4734 - val_accuracy: 0.8819\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 2s 117ms/step - loss: 0.3915 - accuracy: 0.9045 - val_loss: 0.4427 - val_accuracy: 0.8681\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 2s 117ms/step - loss: 0.3643 - accuracy: 0.9115 - val_loss: 0.4322 - val_accuracy: 0.8958\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 2s 117ms/step - loss: 0.3475 - accuracy: 0.9271 - val_loss: 0.4043 - val_accuracy: 0.8819\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 2s 117ms/step - loss: 0.3213 - accuracy: 0.9271 - val_loss: 0.3873 - val_accuracy: 0.9097\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 2s 117ms/step - loss: 0.2966 - accuracy: 0.9427 - val_loss: 0.3752 - val_accuracy: 0.9097\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 2s 117ms/step - loss: 0.2835 - accuracy: 0.9479 - val_loss: 0.3555 - val_accuracy: 0.9167\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 2s 117ms/step - loss: 0.2658 - accuracy: 0.9531 - val_loss: 0.3418 - val_accuracy: 0.9097\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.2492 - accuracy: 0.9618 - val_loss: 0.3274 - val_accuracy: 0.9167\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.2377 - accuracy: 0.9583 - val_loss: 0.3268 - val_accuracy: 0.9028\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 0.2246 - accuracy: 0.9635 - val_loss: 0.3095 - val_accuracy: 0.9306\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.2121 - accuracy: 0.9635 - val_loss: 0.3056 - val_accuracy: 0.9028\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.2047 - accuracy: 0.9635 - val_loss: 0.2888 - val_accuracy: 0.9167\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.1927 - accuracy: 0.9705 - val_loss: 0.2867 - val_accuracy: 0.8958\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 2s 115ms/step - loss: 0.1857 - accuracy: 0.9705 - val_loss: 0.2744 - val_accuracy: 0.9167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/200\n",
      "18/18 [==============================] - 2s 117ms/step - loss: 0.1750 - accuracy: 0.9705 - val_loss: 0.2700 - val_accuracy: 0.9097\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 2s 117ms/step - loss: 0.1671 - accuracy: 0.9757 - val_loss: 0.2587 - val_accuracy: 0.9306\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.1606 - accuracy: 0.9722 - val_loss: 0.2566 - val_accuracy: 0.9167\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.1549 - accuracy: 0.9792 - val_loss: 0.2502 - val_accuracy: 0.9167\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.1482 - accuracy: 0.9809 - val_loss: 0.2432 - val_accuracy: 0.9375\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.1456 - accuracy: 0.9826 - val_loss: 0.2481 - val_accuracy: 0.9236\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.1384 - accuracy: 0.9844 - val_loss: 0.2397 - val_accuracy: 0.9097\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.1317 - accuracy: 0.9844 - val_loss: 0.2299 - val_accuracy: 0.9375\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.1286 - accuracy: 0.9844 - val_loss: 0.2250 - val_accuracy: 0.9375\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - 2s 115ms/step - loss: 0.1221 - accuracy: 0.9878 - val_loss: 0.2234 - val_accuracy: 0.9306\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.1178 - accuracy: 0.9913 - val_loss: 0.2184 - val_accuracy: 0.9375\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - 2s 117ms/step - loss: 0.1136 - accuracy: 0.9896 - val_loss: 0.2160 - val_accuracy: 0.9236\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - 2s 115ms/step - loss: 0.1093 - accuracy: 0.9896 - val_loss: 0.2093 - val_accuracy: 0.9375\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.1058 - accuracy: 0.9913 - val_loss: 0.2069 - val_accuracy: 0.9375\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - 2s 117ms/step - loss: 0.1025 - accuracy: 0.9931 - val_loss: 0.2053 - val_accuracy: 0.9306\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0995 - accuracy: 0.9948 - val_loss: 0.2004 - val_accuracy: 0.9375\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0990 - accuracy: 0.9931 - val_loss: 0.1985 - val_accuracy: 0.9375\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0943 - accuracy: 0.9948 - val_loss: 0.1969 - val_accuracy: 0.9306\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0903 - accuracy: 0.9948 - val_loss: 0.1929 - val_accuracy: 0.9444\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0878 - accuracy: 0.9948 - val_loss: 0.1940 - val_accuracy: 0.9306\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - 2s 117ms/step - loss: 0.0856 - accuracy: 0.9948 - val_loss: 0.1901 - val_accuracy: 0.9306\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0821 - accuracy: 0.9931 - val_loss: 0.1892 - val_accuracy: 0.9306\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0796 - accuracy: 0.9965 - val_loss: 0.1845 - val_accuracy: 0.9375\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0773 - accuracy: 0.9965 - val_loss: 0.1828 - val_accuracy: 0.9306\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0749 - accuracy: 0.9965 - val_loss: 0.1793 - val_accuracy: 0.9375\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0763 - accuracy: 0.9965 - val_loss: 0.1783 - val_accuracy: 0.9444\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - 2s 117ms/step - loss: 0.0761 - accuracy: 0.9948 - val_loss: 0.1882 - val_accuracy: 0.9375\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - 2s 117ms/step - loss: 0.0710 - accuracy: 0.9965 - val_loss: 0.1750 - val_accuracy: 0.9375\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0673 - accuracy: 0.9965 - val_loss: 0.1732 - val_accuracy: 0.9375\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0656 - accuracy: 0.9965 - val_loss: 0.1707 - val_accuracy: 0.9375\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0648 - accuracy: 0.9983 - val_loss: 0.1723 - val_accuracy: 0.9306\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0620 - accuracy: 0.9965 - val_loss: 0.1686 - val_accuracy: 0.9444\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - 2s 117ms/step - loss: 0.0600 - accuracy: 0.9965 - val_loss: 0.1671 - val_accuracy: 0.9375\n",
      "Epoch 57/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0593 - accuracy: 1.0000 - val_loss: 0.1672 - val_accuracy: 0.9306\n",
      "Epoch 58/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0570 - accuracy: 0.9983 - val_loss: 0.1641 - val_accuracy: 0.9444\n",
      "Epoch 59/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0558 - accuracy: 0.9983 - val_loss: 0.1645 - val_accuracy: 0.9375\n",
      "Epoch 60/200\n",
      "18/18 [==============================] - 2s 117ms/step - loss: 0.0546 - accuracy: 0.9983 - val_loss: 0.1624 - val_accuracy: 0.9375\n",
      "Epoch 61/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0538 - accuracy: 1.0000 - val_loss: 0.1629 - val_accuracy: 0.9375\n",
      "Epoch 62/200\n",
      "18/18 [==============================] - 2s 117ms/step - loss: 0.0522 - accuracy: 1.0000 - val_loss: 0.1608 - val_accuracy: 0.9444\n",
      "Epoch 63/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0510 - accuracy: 0.9983 - val_loss: 0.1583 - val_accuracy: 0.9444\n",
      "Epoch 64/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0501 - accuracy: 1.0000 - val_loss: 0.1606 - val_accuracy: 0.9375\n",
      "Epoch 65/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0489 - accuracy: 1.0000 - val_loss: 0.1567 - val_accuracy: 0.9375\n",
      "Epoch 66/200\n",
      "18/18 [==============================] - 2s 117ms/step - loss: 0.0477 - accuracy: 1.0000 - val_loss: 0.1564 - val_accuracy: 0.9444\n",
      "Epoch 67/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0470 - accuracy: 0.9983 - val_loss: 0.1552 - val_accuracy: 0.9444\n",
      "Epoch 68/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0464 - accuracy: 0.9983 - val_loss: 0.1532 - val_accuracy: 0.9444\n",
      "Epoch 69/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0460 - accuracy: 1.0000 - val_loss: 0.1572 - val_accuracy: 0.9375\n",
      "Epoch 70/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0438 - accuracy: 1.0000 - val_loss: 0.1519 - val_accuracy: 0.9444\n",
      "Epoch 71/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0432 - accuracy: 1.0000 - val_loss: 0.1502 - val_accuracy: 0.9514\n",
      "Epoch 72/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0418 - accuracy: 1.0000 - val_loss: 0.1531 - val_accuracy: 0.9375\n",
      "Epoch 73/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0409 - accuracy: 1.0000 - val_loss: 0.1490 - val_accuracy: 0.9444\n",
      "Epoch 74/200\n",
      "18/18 [==============================] - 2s 117ms/step - loss: 0.0397 - accuracy: 1.0000 - val_loss: 0.1485 - val_accuracy: 0.9375\n",
      "Epoch 75/200\n",
      "18/18 [==============================] - 2s 117ms/step - loss: 0.0391 - accuracy: 1.0000 - val_loss: 0.1502 - val_accuracy: 0.9375\n",
      "Epoch 76/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0383 - accuracy: 1.0000 - val_loss: 0.1480 - val_accuracy: 0.9375\n",
      "Epoch 77/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0374 - accuracy: 1.0000 - val_loss: 0.1465 - val_accuracy: 0.9375\n",
      "Epoch 78/200\n",
      "18/18 [==============================] - 2s 117ms/step - loss: 0.0366 - accuracy: 1.0000 - val_loss: 0.1453 - val_accuracy: 0.9444\n",
      "Epoch 79/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0358 - accuracy: 1.0000 - val_loss: 0.1459 - val_accuracy: 0.9375\n",
      "Epoch 80/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0351 - accuracy: 1.0000 - val_loss: 0.1454 - val_accuracy: 0.9375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/200\n",
      "18/18 [==============================] - 2s 117ms/step - loss: 0.0344 - accuracy: 1.0000 - val_loss: 0.1433 - val_accuracy: 0.9514\n",
      "Epoch 82/200\n",
      "18/18 [==============================] - 2s 117ms/step - loss: 0.0346 - accuracy: 1.0000 - val_loss: 0.1453 - val_accuracy: 0.9375\n",
      "Epoch 83/200\n",
      "18/18 [==============================] - 2s 117ms/step - loss: 0.0333 - accuracy: 1.0000 - val_loss: 0.1417 - val_accuracy: 0.9514\n",
      "Epoch 84/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0328 - accuracy: 1.0000 - val_loss: 0.1416 - val_accuracy: 0.9444\n",
      "Epoch 85/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0318 - accuracy: 1.0000 - val_loss: 0.1426 - val_accuracy: 0.9375\n",
      "Epoch 86/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0314 - accuracy: 1.0000 - val_loss: 0.1406 - val_accuracy: 0.9514\n",
      "Epoch 87/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0310 - accuracy: 1.0000 - val_loss: 0.1402 - val_accuracy: 0.9444\n",
      "Epoch 88/200\n",
      "18/18 [==============================] - 2s 117ms/step - loss: 0.0302 - accuracy: 1.0000 - val_loss: 0.1397 - val_accuracy: 0.9514\n",
      "Epoch 89/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0296 - accuracy: 1.0000 - val_loss: 0.1391 - val_accuracy: 0.9444\n",
      "Epoch 90/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0300 - accuracy: 1.0000 - val_loss: 0.1439 - val_accuracy: 0.9375\n",
      "Epoch 91/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0292 - accuracy: 1.0000 - val_loss: 0.1376 - val_accuracy: 0.9514\n",
      "Epoch 92/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0279 - accuracy: 1.0000 - val_loss: 0.1397 - val_accuracy: 0.9375\n",
      "Epoch 93/200\n",
      "18/18 [==============================] - 2s 117ms/step - loss: 0.0277 - accuracy: 1.0000 - val_loss: 0.1364 - val_accuracy: 0.9514\n",
      "Epoch 94/200\n",
      "18/18 [==============================] - 2s 117ms/step - loss: 0.0270 - accuracy: 1.0000 - val_loss: 0.1374 - val_accuracy: 0.9444\n",
      "Epoch 95/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0267 - accuracy: 1.0000 - val_loss: 0.1366 - val_accuracy: 0.9514\n",
      "Epoch 96/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0260 - accuracy: 1.0000 - val_loss: 0.1367 - val_accuracy: 0.9444\n",
      "Epoch 97/200\n",
      "18/18 [==============================] - 2s 117ms/step - loss: 0.0257 - accuracy: 1.0000 - val_loss: 0.1364 - val_accuracy: 0.9444\n",
      "Epoch 98/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0252 - accuracy: 1.0000 - val_loss: 0.1338 - val_accuracy: 0.9514\n",
      "Epoch 99/200\n",
      "18/18 [==============================] - 2s 117ms/step - loss: 0.0247 - accuracy: 1.0000 - val_loss: 0.1349 - val_accuracy: 0.9444\n",
      "Epoch 100/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0245 - accuracy: 1.0000 - val_loss: 0.1346 - val_accuracy: 0.9514\n",
      "Epoch 101/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0241 - accuracy: 1.0000 - val_loss: 0.1340 - val_accuracy: 0.9444\n",
      "Epoch 102/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0236 - accuracy: 1.0000 - val_loss: 0.1327 - val_accuracy: 0.9514\n",
      "Epoch 103/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0234 - accuracy: 1.0000 - val_loss: 0.1327 - val_accuracy: 0.9514\n",
      "Epoch 104/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0231 - accuracy: 1.0000 - val_loss: 0.1332 - val_accuracy: 0.9444\n",
      "Epoch 105/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0224 - accuracy: 1.0000 - val_loss: 0.1318 - val_accuracy: 0.9514\n",
      "Epoch 106/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0222 - accuracy: 1.0000 - val_loss: 0.1312 - val_accuracy: 0.9514\n",
      "Epoch 107/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0218 - accuracy: 1.0000 - val_loss: 0.1327 - val_accuracy: 0.9444\n",
      "Epoch 108/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0215 - accuracy: 1.0000 - val_loss: 0.1308 - val_accuracy: 0.9444\n",
      "Epoch 109/200\n",
      "18/18 [==============================] - 2s 117ms/step - loss: 0.0209 - accuracy: 1.0000 - val_loss: 0.1316 - val_accuracy: 0.9444\n",
      "Epoch 110/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0207 - accuracy: 1.0000 - val_loss: 0.1295 - val_accuracy: 0.9444\n",
      "Epoch 111/200\n",
      "18/18 [==============================] - 2s 115ms/step - loss: 0.0204 - accuracy: 1.0000 - val_loss: 0.1310 - val_accuracy: 0.9514\n",
      "Epoch 112/200\n",
      "18/18 [==============================] - 2s 117ms/step - loss: 0.0201 - accuracy: 1.0000 - val_loss: 0.1328 - val_accuracy: 0.9375\n",
      "Epoch 113/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0197 - accuracy: 1.0000 - val_loss: 0.1290 - val_accuracy: 0.9514\n",
      "Epoch 114/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0195 - accuracy: 1.0000 - val_loss: 0.1307 - val_accuracy: 0.9514\n",
      "Epoch 115/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0189 - accuracy: 1.0000 - val_loss: 0.1283 - val_accuracy: 0.9514\n",
      "Epoch 116/200\n",
      "18/18 [==============================] - 2s 117ms/step - loss: 0.0188 - accuracy: 1.0000 - val_loss: 0.1290 - val_accuracy: 0.9444\n",
      "Epoch 117/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0186 - accuracy: 1.0000 - val_loss: 0.1282 - val_accuracy: 0.9444\n",
      "Epoch 118/200\n",
      "18/18 [==============================] - 2s 117ms/step - loss: 0.0182 - accuracy: 1.0000 - val_loss: 0.1283 - val_accuracy: 0.9444\n",
      "Epoch 119/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0179 - accuracy: 1.0000 - val_loss: 0.1283 - val_accuracy: 0.9514\n",
      "Epoch 120/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0176 - accuracy: 1.0000 - val_loss: 0.1271 - val_accuracy: 0.9444\n",
      "Epoch 121/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0173 - accuracy: 1.0000 - val_loss: 0.1273 - val_accuracy: 0.9444\n",
      "Epoch 122/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0171 - accuracy: 1.0000 - val_loss: 0.1274 - val_accuracy: 0.9444\n",
      "Epoch 123/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0169 - accuracy: 1.0000 - val_loss: 0.1268 - val_accuracy: 0.9583\n",
      "Epoch 124/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0165 - accuracy: 1.0000 - val_loss: 0.1264 - val_accuracy: 0.9444\n",
      "Epoch 125/200\n",
      "18/18 [==============================] - 2s 117ms/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 0.1262 - val_accuracy: 0.9444\n",
      "Epoch 126/200\n",
      "18/18 [==============================] - 2s 117ms/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 0.1264 - val_accuracy: 0.9514\n",
      "Epoch 127/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0159 - accuracy: 1.0000 - val_loss: 0.1267 - val_accuracy: 0.9514\n",
      "Epoch 128/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 0.1264 - val_accuracy: 0.9583\n",
      "Epoch 129/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0155 - accuracy: 1.0000 - val_loss: 0.1250 - val_accuracy: 0.9444\n",
      "Epoch 130/200\n",
      "18/18 [==============================] - 2s 117ms/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 0.1245 - val_accuracy: 0.9444\n",
      "Epoch 131/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 0.1253 - val_accuracy: 0.9514\n",
      "Epoch 132/200\n",
      "18/18 [==============================] - 2s 117ms/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 0.1264 - val_accuracy: 0.9444\n",
      "Epoch 133/200\n",
      "18/18 [==============================] - 2s 117ms/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 0.1244 - val_accuracy: 0.9444\n",
      "Epoch 134/200\n",
      "18/18 [==============================] - 2s 115ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 0.1236 - val_accuracy: 0.9583\n",
      "Epoch 135/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 0.1249 - val_accuracy: 0.9514\n",
      "Epoch 136/200\n",
      "18/18 [==============================] - 2s 115ms/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 0.1236 - val_accuracy: 0.9514\n",
      "Epoch 137/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 0.1237 - val_accuracy: 0.9514\n",
      "Epoch 138/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 0.1236 - val_accuracy: 0.9514\n",
      "Epoch 139/200\n",
      "18/18 [==============================] - 2s 117ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 0.1240 - val_accuracy: 0.9514\n",
      "Epoch 140/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 0.1231 - val_accuracy: 0.9444\n",
      "Epoch 141/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 0.1232 - val_accuracy: 0.9514\n",
      "Epoch 142/200\n",
      "18/18 [==============================] - 2s 115ms/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 0.1231 - val_accuracy: 0.9514\n",
      "Epoch 143/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 0.1221 - val_accuracy: 0.9444\n",
      "Epoch 144/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 0.1227 - val_accuracy: 0.9514\n",
      "Epoch 145/200\n",
      "18/18 [==============================] - 2s 117ms/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 0.1226 - val_accuracy: 0.9514\n",
      "Epoch 146/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.1227 - val_accuracy: 0.9514\n",
      "Epoch 147/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 0.1226 - val_accuracy: 0.9444\n",
      "Epoch 148/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 0.1215 - val_accuracy: 0.9583\n",
      "Epoch 149/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.1217 - val_accuracy: 0.9514\n",
      "Epoch 150/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 0.1216 - val_accuracy: 0.9514\n",
      "Epoch 151/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.1216 - val_accuracy: 0.9514\n",
      "Epoch 152/200\n",
      "18/18 [==============================] - 2s 117ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 0.1221 - val_accuracy: 0.9514\n",
      "Epoch 153/200\n",
      "18/18 [==============================] - 2s 115ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 0.1213 - val_accuracy: 0.9514\n",
      "Epoch 154/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.1221 - val_accuracy: 0.9514\n",
      "Epoch 155/200\n",
      "18/18 [==============================] - 2s 115ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.1209 - val_accuracy: 0.9514\n",
      "Epoch 156/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.1212 - val_accuracy: 0.9514\n",
      "Epoch 157/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.1204 - val_accuracy: 0.9514\n",
      "Epoch 158/200\n",
      "18/18 [==============================] - 2s 115ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.1207 - val_accuracy: 0.9514\n",
      "Epoch 159/200\n",
      "18/18 [==============================] - 2s 117ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.1214 - val_accuracy: 0.9514\n",
      "Epoch 160/200\n",
      "18/18 [==============================] - 2s 117ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.1194 - val_accuracy: 0.9583\n",
      "Epoch 161/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.1193 - val_accuracy: 0.9514\n",
      "Epoch 162/200\n",
      "18/18 [==============================] - 2s 115ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.1203 - val_accuracy: 0.9514\n",
      "Epoch 163/200\n",
      "18/18 [==============================] - 2s 117ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.1196 - val_accuracy: 0.9583\n",
      "Epoch 164/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.1194 - val_accuracy: 0.9514\n",
      "Epoch 165/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.1199 - val_accuracy: 0.9514\n",
      "Epoch 166/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.1185 - val_accuracy: 0.9583\n",
      "Epoch 167/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.1204 - val_accuracy: 0.9514\n",
      "Epoch 168/200\n",
      "18/18 [==============================] - 2s 117ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.1194 - val_accuracy: 0.9514\n",
      "Epoch 169/200\n",
      "18/18 [==============================] - 2s 117ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.1189 - val_accuracy: 0.9583\n",
      "Epoch 170/200\n",
      "18/18 [==============================] - 2s 117ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.1196 - val_accuracy: 0.9514\n",
      "Epoch 171/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.1184 - val_accuracy: 0.9514\n",
      "Epoch 172/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.1190 - val_accuracy: 0.9514\n",
      "Epoch 173/200\n",
      "18/18 [==============================] - 2s 115ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.1184 - val_accuracy: 0.9583\n",
      "Epoch 174/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.1186 - val_accuracy: 0.9583\n",
      "Epoch 175/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.1182 - val_accuracy: 0.9514\n",
      "Epoch 176/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.1182 - val_accuracy: 0.9514\n",
      "Epoch 177/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.1182 - val_accuracy: 0.9514\n",
      "Epoch 178/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.1186 - val_accuracy: 0.9514\n",
      "Epoch 179/200\n",
      "18/18 [==============================] - 2s 117ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.1184 - val_accuracy: 0.9514\n",
      "Epoch 180/200\n",
      "18/18 [==============================] - 2s 115ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.1181 - val_accuracy: 0.9583\n",
      "Epoch 181/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.1183 - val_accuracy: 0.9514\n",
      "Epoch 182/200\n",
      "18/18 [==============================] - 2s 129ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.1177 - val_accuracy: 0.9583\n",
      "Epoch 183/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.1181 - val_accuracy: 0.9583\n",
      "Epoch 184/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.1180 - val_accuracy: 0.9514\n",
      "Epoch 185/200\n",
      "18/18 [==============================] - 2s 117ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.1176 - val_accuracy: 0.9514\n",
      "Epoch 186/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.1171 - val_accuracy: 0.9514\n",
      "Epoch 187/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.1174 - val_accuracy: 0.9514\n",
      "Epoch 188/200\n",
      "18/18 [==============================] - 2s 117ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.1181 - val_accuracy: 0.9514\n",
      "Epoch 189/200\n",
      "18/18 [==============================] - 2s 117ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.1168 - val_accuracy: 0.9583\n",
      "Epoch 190/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.1170 - val_accuracy: 0.9514\n",
      "Epoch 191/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.1173 - val_accuracy: 0.9583\n",
      "Epoch 192/200\n",
      "18/18 [==============================] - 2s 117ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.1172 - val_accuracy: 0.9514\n",
      "Epoch 193/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.1181 - val_accuracy: 0.9514\n",
      "Epoch 194/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.1167 - val_accuracy: 0.9583\n",
      "Epoch 195/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.1171 - val_accuracy: 0.9514\n",
      "Epoch 196/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.1169 - val_accuracy: 0.9514\n",
      "Epoch 197/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.1169 - val_accuracy: 0.9514\n",
      "Epoch 198/200\n",
      "18/18 [==============================] - 2s 117ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.1166 - val_accuracy: 0.9514\n",
      "Epoch 199/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.1168 - val_accuracy: 0.9514\n",
      "Epoch 200/200\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.1160 - val_accuracy: 0.9583\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained ResNet50 model and remove the top classification layer\n",
    "resnet_base_model = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape_resnet)\n",
    "resnet_base_model.trainable = False\n",
    "\n",
    "# Add custom classification head to the ResNet model\n",
    "resnet_global_avg_pooling = GlobalAveragePooling2D()(resnet_base_model.output)\n",
    "resnet_output = Dense(6, activation='softmax')(resnet_global_avg_pooling)\n",
    "resnet_model = Model(inputs=resnet_base_model.input, outputs=resnet_output)\n",
    "\n",
    "# Compile the ResNet model\n",
    "resnet_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "densenet_base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=input_shape_densenet)\n",
    "densenet_base_model.trainable = False\n",
    "\n",
    "\n",
    "densenet_global_avg_pooling = GlobalAveragePooling2D()(densenet_base_model.output)\n",
    "densenet_output = Dense(6, activation='softmax')(densenet_global_avg_pooling)\n",
    "densenet_model = Model(inputs=densenet_base_model.input, outputs=densenet_output)\n",
    "\n",
    "\n",
    "densenet_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', patience=10, factor=0.5, min_lr=1e-7)\n",
    "\n",
    "# Train the models\n",
    "'''\n",
    "train the models on resized training data and validation split,\n",
    "monitoring the validation loss and using the\n",
    "early stopping and learning rate scheduling callbacks to stop when necessary.\n",
    "'''\n",
    "\n",
    "resnet_history = resnet_model.fit(X_train_resized_resize=32, epochs=200, validation_split=0.2,callbacks=[early_stopping, lr_scheduler])net, y_train, batch_size=32, epochs=200, validation_split=0.2,callbacks=[early_stopping, lr_scheduler])\n",
    "densenet_history = densenet_model.fit(X_train_resized_densenet, y_train, batch_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d960ad4a",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1261658693.py, line 12)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_2035/1261658693.py\"\u001b[0;36m, line \u001b[0;32m12\u001b[0m\n\u001b[0;31m    6/6 [==============================] - 3s 480ms/step - loss: 0.2226 - accuracy: 0.9333\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Resize test images to the input shape required by each model\n",
    "X_test_resized_densenet = resize_images(X_test, input_shape_densenet)\n",
    "X_test_resized_resnet = resize_images(X_test, input_shape_resnet)\n",
    "\n",
    "# Evaluate the models on test data\n",
    "densenet_loss, densenet_accuracy = densenet_model.evaluate(X_test_resized_densenet, y_test)\n",
    "resnet_loss, resnet_accuracy = resnet_model.evaluate(X_test_resized_resnet, y_test)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"DenseNet Test accuracy:\", densenet_accuracy)\n",
    "print(\"ResNet Test accuracy:\", resnet_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c329fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_learning_curves(history, model_name, ax):\n",
    "    ax.plot(history.history['loss'], label='Training Loss')\n",
    "    ax.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    ax.set_title(f'{model_name} Learning Curve')\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Loss')\n",
    "    ax.legend()\n",
    "\n",
    "\n",
    "def plot_accuracy_curves(history, model_name, ax):\n",
    "    ax.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    ax.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    ax.set_title(f'{model_name} Accuracy Curve')\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Accuracy')\n",
    "    ax.legend()\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(20, 15))\n",
    "plot_learning_curves(densenet_history, 'DenseNet', axs[0, 0])\n",
    "plot_accuracy_curves(densenet_history, 'DenseNet', axs[0, 1])\n",
    "\n",
    "plot_learning_curves(resnet_history, 'ResNet', axs[1, 0])\n",
    "plot_accuracy_curves(resnet_history, 'ResNet', axs[1, 1])\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3260a1ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
